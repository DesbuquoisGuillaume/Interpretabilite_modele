{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interprétabilité des modèles\n",
    "## 0. Overview\n",
    "\n",
    "La montée en complexité des modèles de Machine learning et Deep learning introduit bien souvent des modèles avec d'importantes quantités de paramètres, rendant leurs intérprétations complexes.\n",
    "\n",
    "Pourtant, il est très important d'être capable de comprendre les décisions prises par un modèle. Cela permet avant tout de les optimiser, mais aussi de les rendre plus accessibles pour des pôles plus orientés métiers.\n",
    "\n",
    "=> **L'objectif de ce notebook est la mise en pratique de l'interprétabilité des modèles sur des cas concrets**\n",
    "\n",
    "### 0.1 Données\n",
    "\n",
    "Pour la suite de ce notebook, nous nous baserons sur 2 jeux de données connus :\n",
    "* **boston** : ce dataset vise à déterminer le prix de vente des maisons de Boston en fonction de différents indicateurs\n",
    "* **iris** : ce dataset vise à classifier des iris suivant 3 catégories en fonction de différentes informations sur les fleurs\n",
    "\n",
    "Nous commencerons par utiliser le jeu de données **boston**. Son importation est disponible ci-dessous. Vous retrouverez aussi le dictionnaire des variables présentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns=[\"Houses prices\"])\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Focus sur les Forêts Aléatoires en Régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # On enlève les warnings pour la suite du notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Idée générale\n",
    "\n",
    "Beaucoup d'ouvrages traitant des **Forêts Aléatoires** considèrent ces modèles comme *black-blox*. En cause : le grand nombre d'arbres profonds, où chaque arbre est entrainé sur un échantillon bootstrap, et ou chaque noeud de l'arbre est partitionné sur la base d'un sous échantillon de variables tiré aléatoirement.\n",
    "\n",
    "Il est donc compliqué d'avoir une compréhension complète du processus de décision. Une solution généralement apportée est de calculer l'importance des variables du modèle. L'idée est de permuter les valeurs de chaque variable une à une, et de déterminer quelle permutation à le plus d'impact sur la performance du modèle.\n",
    "\n",
    "\n",
    "L'approche sur laquelle nous allons nous baser est différente, et s'appuie sur les **chemins de décisions** formés par les arbres. Lorsque l'on s'intéresse à un arbre de décision, il est assez intuitif qu'il existe, pour chaque décision, un chemin partant du noeud racine jusqu'à un noeud terminal. Ce chemin est constitué d'une série de décisions basées sur une ou plusieurs variables, qui contribuent donc à la prédiction.\n",
    "\n",
    "#### 1.2.1 L'approche des chemins de décision\n",
    "\n",
    "Un arbre de décision avec $M$ noeuds divise l'espace des données en $M$ régions, notées $R_m, 1≤m≤M$. De manière générale, si l'on définit $x$ une nouvelle observation et $f$ la fonction de prédiction de l'arbre, on a :\n",
    "\n",
    "<center> $ f(x) = \\sum\\limits_{m=1}^{M}c_m \\mathbb{1}_{(x\\ \\in \\ R_m)} $ </center> \n",
    "\n",
    "Avec :\n",
    "* $c_m$ la valeur de sortie pour la région $R_m$. $c_m$ est déterminée lors de la phase d'apprentissage de l'arbre\n",
    "* $\\mathbb{1}_{(x\\ \\in \\ R_m)}$ la fonction indicatrice renvoyant 1 si $x\\ \\in \\ R_m$, 0 sinon\n",
    "\n",
    "##### 1.2.1.1 L'exemple d'un arbre de régression\n",
    "\n",
    "Partons maintenant d'un exemple pour comprendre l'approche des chemins de décision. Nous nous baserons sur le jeu de données **boston**. Pour rappel, on cherche à déterminer le prix des maisons de Boston en fonction de différents indicateurs.\n",
    "\n",
    "\n",
    "<img src=\"Tree2.png\" alt=\"Drawing\" style=\"width: 400px;\" align=\"left\"/>\n",
    "L'image à gauche montre un arbre de régression de pronfondeur 3. On retrouve un champ *Value* en dessous de chaque noeud. Ce dernier représente la moyenne des prix des maisons, et est logiquement différent suivant l'emplacement ou l'on se situe dans l'arbre.\n",
    "\n",
    "Cela permet de suivre l'évolution des prix des maisons suivant les coupures réalisées par différentes variables.\n",
    "\n",
    "Le but principal de cet exemple est de faire apparaître qu'il existe un moyen \"opérationnel\" de décomposer les prédictions au travers des **chemins de décision**.\n",
    "\n",
    "La *Value* du noeud racine (i.e. *22.60* ici) correspond à la moyenne des prix des maisons sur les données d'apprentissage, nous l'appellerons **priormean** par la suite. Ainsi, chaque prédiction partant du noeud racine, peut être définie comme le **priormean** auquel on soustrait ou ajoute les contributions des variables sur le chemin de décision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, pour une nouvelle observation $x$ dont la variable $RM$ est inférieure à *6.94*, on se retrouve à descendre la première branche verte de l'arbre. A ce niveau, les observations de l'échantillon d'apprentissage ont une moyenne des prix des maisons de *37.42*. Le priormean étant de *22.60*, on peut considérer que la contribution de la variable $RM$ à été de faire augmenter la prédiction de *14.82* (*37.42-22.60*).\n",
    "\n",
    "L'opération est donc à répeter au fur et à mesure de la descente de l'arbre jusqu'au noeud terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction de prédiction peut donc se réécrire :\n",
    "\n",
    "<center> $ f(x) = c_{full} + \\sum\\limits_{k=1}^{K}contrib(x,k) $ </center> \n",
    "\n",
    "Avec :\n",
    "* $K$ le nombre de variables\n",
    "* $cfull$ la valeur du noeud racine (*Value* sur l'arbre ci-dessus)\n",
    "* $contrib(x, k)$ la contribution de la $k$-ième variable à la prédiction de $x$. \n",
    "\n",
    "\n",
    "On retrouve quelque chose qui, en apparence, ressemble à une régression linéaire du type $f(x) = ax + b$.\n",
    "Toutefois, en régression linéaire, le vecteur de paramètres $a$ est constant. Dans le cas de l'arbre de décision, les contributions des variables varient suivant le chemin de décision impliqué.\n",
    "\n",
    "Cela permet cependant de décomposer une prédiction et donc de pouvoir plus facilement l'interpréter.\n",
    "\n",
    "#### 1.2.1.2 Le passage aux Forêts Aléatoires\n",
    "\n",
    "L'application de ce principe d'un arbre de décision à une Forêt Aléatoire est relativement simple. En effet, la prédiction d'une forêt est la moyenne des prédictions de ses arbres. Soit $g$ la fonction de prédiction d'une forêt, et $x$ une nouvelle observation. On a :\n",
    "\n",
    "<center> $ g(x) = \\frac{1}{J} \\sum\\limits_{j=1}^{J}f_j(x) $ </center> \n",
    "\n",
    "Avec :\n",
    "* $J$ le nombre d'arbres de la forêt\n",
    "* $f_j(x)$ la préction pour la nouvelle observation $x$ pour l'arbre $j$\n",
    "\n",
    "\n",
    "On peut donc facilement écrire :\n",
    "\n",
    "<center> $ g(x) = \\frac{1}{J} \\sum\\limits_{j=1}^{J}c_{j_{full}} + \\sum\\limits_{k=1}^{K}(\\frac{1}{J}\\sum\\limits_{j=1}^{J}contrib_j(x,k)) $ </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Première décomposition - Simplification du problème\n",
    "\n",
    "Nous allons maintenant chercher à appliquer la décomposition vue précédemment.\n",
    "\n",
    "Dans un premier temps, nous essaierons de décomposer le prix estimé d'une maison $i$ (notre variable cible) comme la somme des contributions de chaque variable pour cette maison, i.e. : \n",
    "<center> $ prediction^i=priormean+contributionVariable_1^i+…+contributionVariable_n^i $ </center> \n",
    "\n",
    "Peu de packages proposent actuellement de rentrer dans ce niveau de détails à l'heure actuelle. Nous nous baserons sur **treeinterpreter**. Ce dernier propose la décomposition exposée au dessus pour différents modèles existants sous *scikit-learn*, tels que :\n",
    "* DecisionTreeRegressor\n",
    "* DecisionTreeClassifier\n",
    "* ExtraTreeRegressor\n",
    "* ExtraTreeClassifier\n",
    "* RandomForestRegressor\n",
    "* RandomForestClassifier\n",
    "* ExtraTreesRegressor\n",
    "* ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Première Forêt Aléatoire\n",
    "**Exercice 1 :**\n",
    "Pour commencer, séparez les données à disposition en 2 échantillons (via la fonction *train_test_split*) en définissant une graîne aléatoire (=1234) :\n",
    "* un échantillon d'apprentissage (2/3 des données)\n",
    "* un échantillon de validation (1/3 des données)\n",
    "\n",
    "Entraînez ensuite une forêt (les paramètres par défaut suffiront pour l'exemple) sur la base de vos données d'apprentissage, en indiquant une graine aléatoire (=1234) pour figer les résultats.\n",
    "\n",
    "*NB : Nous noterons X_train, X_test, y_train, y_test nos échantillons d'apprentissage et de validation, et rf le modèle entraîné*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant choisir 2 points de données de notre échantillon de test, sur lequel nous allons prédire notre cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tworows = X_test.iloc[:2,]\n",
    "for i,prediction in enumerate(rf.predict(tworows)):\n",
    "    print(\"Prédiction pour ligne {} de notre échantillon de test : {}\".format(i,round(prediction,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que les prédictions sont très éloignées pour ces 2 points de données. L'idée est donc de comprendre maintenant quelles sont les variables qui ont le plus contribuées (aussi bien négativement que positivement) aux prédictions.\n",
    "\n",
    "Pour cela, nous allons réaliser la décomposition vue précédemment en utilisant le package **treeinterpreter**.\n",
    "\n",
    "La structure est relativement simple, et nous permet, sur la base d'un modèle déjà entraîné, de récupérer pour des points de données de l'échantillon de test, la prédiction du modèle, le priormean, ainsi que les contributions de chaque variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, priormean, contributions = ti.predict(rf, tworows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on commence par s'intéresser au contenu de *prediction*, on remarque bien que l'on récupère les mêmes valeurs que ci-dessus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le contenu de la variable *priormean*, qui pour rappel correspond à la moyenne de notre variable cible sur l'échantillon d'apprentissage, est logiquement le même qu'importe le point de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priormean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, la variable *contributions* contient deux arrays de dimensions *1x13* chacun, représentant pour chaque prédiction, la contribution de chacune des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc tout ce qui est nécessaire pour déterminer les contributions de chacune des variables aux deux prédictions, en rappelant que :\n",
    "<center> $ prediction=priormean+contributionVariable_1+…+contributionVariable_n $ </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tworows)):\n",
    "    print(\"Point de données {}\".format(i))\n",
    "    print(\"Prior mean {}\".format(priormean[i]))\n",
    "    print(\"Contributions des variables (par décroissance absolue) :\")\n",
    "    for c, feature in sorted(zip(contributions[i], \n",
    "                                 boston.feature_names), \n",
    "                             key=lambda x: -abs(x[0])):\n",
    "        print(\"{} : {}\".format(feature, round(c, 2)))\n",
    "    print(\"-\"*20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2** : A partir des informations récupérées (*priormean* et *contributions*) et sur la base de la décomposition exposée, recalculer les prédictions pour nos 2 points de données de test. Vérifiez qu'elles correspondent bien à ce que nous avions obtenu avec *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce package est donc très pratique pour pouvoir mieux interpréter les prédictions de nos forêts aléatoires pour certains points de données.\n",
    "\n",
    "Le package possède **2 intérêts majeurs** :\n",
    "* Comprendre pourquoi les valeurs prédites sur 2 jeux de données sont différentes, et quelles sont les variables en causes. Sur le jeu de données *boston*, on pourrait par exemple chercher à comprendre d'où viennent les différences de prix des maisons de plusieurs voisinages\n",
    "* Débugger un modèle et/ou les données, en cherchant par exemple à comprendre pourquoi les valeurs prédites sur un nouveau jeu de données ne matchent pas avec celles d'anciennes données\n",
    "\n",
    "=> **Essayons de développer le premier cas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3** : Splitter le jeu de données de test *(X_test)* en 2 sous échantillons (respectivement *ech1* & *ech2*) de tailles égales. Ces échantillons modéliseront 2 voisinages. En utilisant la forêt déjà entraînée, calculez et stockez les prédictions associées à ces 2 sous échantillons. Calculez ensuite la moyenne des prédictions pour *ech1* et *ech2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constater que les prédictions moyennes sont relativement différentes sur les 2 échantillons.\n",
    "\n",
    "**Exerice 4** : Appliquer la décomposition vue précedemment sur les 2 sous échantillons *ech1* et *ech2*. On notera *prediction1, priormean1* et *contributions1* (respectivement *2*) les variables dans lequelles seront stockées les résultats.\n",
    "\n",
    "Moyennez ensuite les contributions par variable pour chaque sous échantillon et stockez les résultats dans deux variables, respectivement *totalc1* et *totalc2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la mesure où les *priormean* sont les mêmes (puisque calculés sur le même échantillon d'apprentissage), la différence entre les prédictions moyennes sur les 2 sous échantillons provient uniquement des contributions des différentes variables.\n",
    "En outre, la différence entre les contributions des variables est égale à la différence entre les prédictions. Ce que nous pouvons facilement vérifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(totalc1 - totalc2),np.mean(prediction1) - np.mean(prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5** : Calculer les différences de contributions de chaque variable entre les 2 sous échantillons, et appuyez vous sur le dictionnaire des données disponible en début de notebook pour interpréter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 Seconde décomposition\n",
    "\n",
    "Rendre les prévisions de nos forêts aléatoires intérprétable semble donc assez simple, et relativement proche de ce que l'on connaît avec des modèles linéaires.\n",
    "\n",
    "Cependant, **cette décomposition est imparfaite, puisqu'elle ne prend pas en compte les intéractions entre variables.**\n",
    "Pour l'illustrer, prenons l'exemple du XOR (= ou exclusif).\n",
    "\n",
    "##### 1.2.4.1 L'exemple du XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'X1': [0, 0, 1, 1], 'X2': [0, 1, 0, 1], 'Sortie': [0, 1, 1, 0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le **XOR** est relativement facile à comprendre. Pour que la valeur de sortie soit Vraie (=1), il faut que l'une seule des valeurs de *X1* ou *X2* soit Vraie (=1).\n",
    "\n",
    "Dans ce cas, ni *X1* ni *X2* n'apporte de l'information sur la valeur de sortie seul. C'est à dire que si l'on isole *X1* ou *X2*, il n'est pas possible de prédire la valeur de *Sortie*.\n",
    "\n",
    "Un arbre de décision va être capable d'apprendre de cet effet et donc de classifier correctement le XOR (arbre ci dessous).\n",
    "\n",
    "<img src=\"Tree.png\" alt=\"Drawing\" style=\"width: 400px;\" align=\"left\"/>\n",
    "\n",
    "Si l'on se penche sur le premier noeud de l'arbre, où seul *X1* est connu, nous ne sommes pas en mesure de savoir si la valeur de *Sortie* est 1 ou 0. La meilleure prédiction possible est donc 0.5 (ce qui revient à dire \"Je ne sais pas\"). De ce fait, la contribution de *X1* si l'on ne considère que ce noeud serait (à tord) 0. *(Un priormean qui vaut 0.50, et les *Value* des deux noeuds suivants aussi à 0.50)*\n",
    "\n",
    "Aux noeuds suivants de l'arbre, nous prenons connaissance de la valeur de *X2*. Nous pouvons donc aisément réaliser la bonne prédiction.\n",
    "Toutefois, attribuer la bonne prédiction à la variable *X2* seule serait faux, puisque **c'est l'intéraction des deux variables qui nous permet de bien prédire la valeur de *sortie*.**\n",
    "Il faut donc répartir la contribution équitablement entre les deux variables.\n",
    "\n",
    "Prenons le <font color='red'>chemin rouge</font> à titre d'exemple. Ce chemin conduit à la prédiction de la valeur 0.\n",
    "\n",
    "On sait que le priormean du modèle est de 0.50.\n",
    "\n",
    "Pour prédire la valeur 0.00, sachant que le *priormean* est de 0.50, et que la contribution de *X1* (i.e. premier noeud) est de 0.00. La contribution de l'intéraction *X1X2* est forcément de -0.50.\n",
    "\n",
    "Cf la décomposition :\n",
    "<center> $ 0.00 = 0.50 (priormean) + 0.00(contrib X1) - 0.5 (contrib X1X2) $ </center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les **effets d'intéractions** peuvent être calculés par le package **treeinterpreter** en passant le paramètre *joint_contribution=True* à la fonction *.predict*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 6**:  Repartir des 2 sous échantillons *ech1* et *ech2* construit à l'**Exercice 3**. Appliquer de nouveau la décomposition vue à l'exercice 4 en faisant attention à inclure les effets d'intéractions. Stockez à nouveau les résultats dans les variables *prediction1, priormean1, contributions1* (respectivement *2* pour l'*ech2*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction *aggregated_contribution* du module *utils* (*utils.aggregated_contribution*), avec en paramètre les contributions obtenues par la fonction *.predict* est très utile lorsque l'on utilise des effets d'intéractions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_contrib1 = utils.aggregated_contribution(contributions1)\n",
    "mean_contrib2 = utils.aggregated_contribution(contributions2)\n",
    "mean_contrib1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 7** : Observez le contenu de la variable *mean_contrib1*. Quel est son type ? A quoi correspond son contenu ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"text-decoration:underline\">Réponse</span> : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 8** : Vérifiez que la différence entre les contributions des variables (et intéractions de variables) sommée est égale à la différence entre les prédictions moyennes entre les 2 sous échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 9** : En sachant que pour un indice de variable donné, il est possible d'en récupérer le nom via le code suivant :\n",
    "`indice_variable = 1\n",
    "boston[\"feature_names\"][indice_variable]`\n",
    "\n",
    "\n",
    "Calculer de nouveau les différences de contributions entre les 2 sous échantillons, en prenant cette fois en compte les intéractions entre variables.\n",
    "Afficher par exemple, les 10 variables/intéractions de variables qui ont le plus contribuées aux écarts de prix entre les 2 échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 10** :  Représenter les *features importances* du modèle *rf*. Interprétez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus sur les Forêts Aléatoires en Classification\n",
    "\n",
    "Nous utiliserons ici le dataset **iris**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.DataFrame(iris.target, columns=[\"Classe\"])\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice Bilan** : Sur la base des données *iris*, appliquez une forêt aléatoire et utilisez le package **treeinterpreter** pour décomposer la prédiction pour certains points de données choisit manuellement.\n",
    "\n",
    "En classification, les fonctions vues précédemment s'utilisent de la même manière mais les sorties sont différentes.. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Décomposer et rendre interprétable les prévisions des forêts aléatoires est finalement assez simple. Cela peut conduire à un niveau d'interprétabilité proche à celui des modèles linéaires. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
