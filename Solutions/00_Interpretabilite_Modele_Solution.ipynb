{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interprétabilité des modèles\n",
    "## 0. Overview\n",
    "\n",
    "Les enjeux derrière l'interprétabilité des modèles, ses motivations ainsi que des méthodes pour les appliquer ont été présentées par **Maxence Brochard**. Vous pouvez à tout moment retrouver les ressources ici : https://lion.app.box.com/folder/65170147483 \n",
    "\n",
    "=> **L'objectif de ce notebook est la mise en pratique de l'interprétabilité des modèles sur des cas concrets**\n",
    "\n",
    "### 0.1 Données\n",
    "\n",
    "Pour la suite de ce notebook, nous nous baserons sur 2 jeux de données connus :\n",
    "* **boston** : ce dataset vise à déterminer le prix de vente des maisons de Boston en fonction de différents indicateurs\n",
    "* **iris** : ce dataset vise à classifier des iris suivant 3 catégories en fonction de différentes informations sur les fleurs\n",
    "\n",
    "Nous commencerons par utiliser le jeu de données **boston**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "boston = load_boston()\n",
    "X = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y = pd.DataFrame(boston.target, columns=[\"Houses prices\"])\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Focus sur les Random Forests en Régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, vous devez installer le package **treeinterpreter** : `pip install treeinterpreter` dans votre CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import des packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # On enlève les warnings pour la suite du notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treeinterpreter import treeinterpreter as ti, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Idée générale\n",
    "\n",
    "Nous allons essayer de nous intéresser un peu plus en profondeur aux Random Forests, et plus particulièrement aux prédictions obtenus par ces modèles, en cherchant à les décomposer.\n",
    "\n",
    "#### 1.2.1 Première décomposition - Simplification du problème\n",
    "\n",
    "Dans un premier temps, nous essaierons de décomposer le prix estimé pour une maison *i* comme la somme des contributions de chaque variable pour cette maison, i.e. : \n",
    "<center> $ prediction^i=biais+contributionVariable_1^i+…+contributionVariable_n^i $ </center> \n",
    "\n",
    "Peu de packages proposent actuellement de rentrer dans ce niveau de détails à l'heure actuelle. Nous nous baserons sur **treeinterpreter**. Ce dernier propose la décomposition exposée au dessus pour différents modèles existants sous *scikit-learn*, tels que :\n",
    "* DecisionTreeRegressor\n",
    "* DecisionTreeClassifier\n",
    "* ExtraTreeRegressor\n",
    "* ExtraTreeClassifier\n",
    "* RandomForestRegressor\n",
    "* RandomForestClassifier\n",
    "* ExtraTreesRegressor\n",
    "* ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Première Random Forest\n",
    "**Exercice 1 :**\n",
    "Pour commencer, séparez les données à disposition en 2 échantillons (via la fonction *train_test_split*) en définissant une graîne aléatoire (=1234) :\n",
    "* un échantillon d'apprentissage (2/3 des données)\n",
    "* un échantillon de validation (1/3 des données)\n",
    "\n",
    "Entraînez ensuite une Random Forest (les paramètres par défaut suffiront pour l'exemple) sur la base de vos données d'apprentissage, en indiquant une graine aléatoire (=1234) pour figer les résultats.\n",
    "\n",
    "*NB : Nous noterons X_train, X_test, y_train, y_test nos échantillons d'apprentissage et de validation, et rf le modèle entraîné*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=1234, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=1/3, random_state=1234)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=1234)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant choisir 2 points de données de notre échantillon de test, sur lequel nous allons prédire notre cible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédiction pour ligne 0 de notre échantillon de test : 32.18\n",
      "Prédiction pour ligne 1 de notre échantillon de test : 23.78\n"
     ]
    }
   ],
   "source": [
    "tworows = X_test.iloc[:2,]\n",
    "for i,prediction in enumerate(rf.predict(tworows)):\n",
    "    print(\"Prédiction pour ligne {} de notre échantillon de test : {}\".format(i,round(prediction,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que les prédictions sont très éloignées pour ces 2 points de données. L'idée est donc de comprendre maintenant quelles sont les variables qui ont le plus contribuées (aussi bien négativement que positivement) aux prédictions.\n",
    "\n",
    "Pour cela, nous allons utiliser le package **treeinterpreter**.\n",
    "\n",
    "La structure est relativement simple, et nous permet, sur la base d'un modèle déjà entraîné, de récupérer pour des points de données de l'échantillon de test, la prédiction du modèle, le biais, ainsi que les contributions de chaque variable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, biais, contributions = ti.predict(rf, tworows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on commence par s'intéresser au contenu de *prediction*, on remarque bien qu'on récupère les mêmes valeurs que ci-dessus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32.18],\n",
       "       [23.78]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le contenu de la variable *biais*, qui correspond à la moyenne sur l'échantillon d'apprentissage, est logiquement le même qu'importe le point de données de test.\n",
    "\n",
    "Nous reviendrons dessus par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.424273, 22.424273])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, la variable *contributions* contient deux arrays de dimensions *1x13* chacun, représentant pour chaque prédiction, la contribution de chacune des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.60555556e-01,  0.00000000e+00,  7.50000000e-02,\n",
       "         0.00000000e+00,  2.46911765e-01,  6.68611695e+00,\n",
       "         4.71296296e-03, -9.32726952e-01,  4.50000000e-02,\n",
       "         1.76981430e+00,  1.61194290e-01, -2.28973138e-01,\n",
       "         1.26812127e+00],\n",
       "       [-2.89914054e-01, -8.12566845e-02, -7.07142857e-02,\n",
       "         0.00000000e+00,  1.82911765e-01,  1.84975041e-01,\n",
       "        -2.87870370e-02,  7.94091021e-02,  2.83180189e-01,\n",
       "        -3.20409387e-02, -1.88606092e+00, -6.34404762e-02,\n",
       "         3.07746530e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc tout ce qui est nécessaire pour déterminer les contributions de chacune des variables aux deux prédictions, en rappelant que :\n",
    "<center> $ prediction=biais+contributionVariable1+…+contributionVariablen $ </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point de données 0\n",
      "Biais 22.424272997032645\n",
      "Contributions des variables (par décroissance absolue) :\n",
      "RM : 6.69\n",
      "TAX : 1.77\n",
      "LSTAT : 1.27\n",
      "DIS : -0.93\n",
      "CRIM : 0.66\n",
      "NOX : 0.25\n",
      "B : -0.23\n",
      "PTRATIO : 0.16\n",
      "INDUS : 0.07\n",
      "RAD : 0.05\n",
      "AGE : 0.0\n",
      "ZN : 0.0\n",
      "CHAS : 0.0\n",
      "--------------------\n",
      "Point de données 1\n",
      "Biais 22.424272997032645\n",
      "Contributions des variables (par décroissance absolue) :\n",
      "LSTAT : 3.08\n",
      "PTRATIO : -1.89\n",
      "CRIM : -0.29\n",
      "RAD : 0.28\n",
      "RM : 0.18\n",
      "NOX : 0.18\n",
      "ZN : -0.08\n",
      "DIS : 0.08\n",
      "INDUS : -0.07\n",
      "B : -0.06\n",
      "TAX : -0.03\n",
      "AGE : -0.03\n",
      "CHAS : 0.0\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tworows)):\n",
    "    print(\"Point de données {}\".format(i))\n",
    "    print(\"Biais {}\".format(biais[i]))\n",
    "    print(\"Contributions des variables (par décroissance absolue) :\")\n",
    "    for c, feature in sorted(zip(contributions[i], \n",
    "                                 boston.feature_names), \n",
    "                             key=lambda x: -abs(x[0])):\n",
    "        print(\"{} : {}\".format(feature, round(c, 2)))\n",
    "    print(\"-\"*20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 2** : A partir des informations récupérées (*biais* et *contributions*) grâce au module *.predict* du package **treeinterpreter**, recalculer les prédictions pour nos 2 points de données de test, et vérifier qu'elles correspondent bien à ce que nous avions obtenu avec *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[32.18],\n",
       "        [23.78]]), array([32.18, 23.78]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction,biais + np.sum(contributions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce package est donc très pratique pour pouvoir mieux interpréter les prédictions de nos modèles de Random Forests pour certains points de données.\n",
    "\n",
    "On y trouve **2 intérêts majeurs** :\n",
    "* Comprendre pourquoi les valeurs prédites sur 2 jeux de données sont différentes, et quelles sont les variables en causes. Sur nos données d'exemple, on pourrait par exemple chercher à comprendre d'où viennent les différences de prix des maisons de plusieurs voisinages\n",
    "* Débugger un modèle et/ou les données, en cherchant par exemple à comprendre pourquoi les valeurs prédites sur un nouveau jeu de données ne matchent pas avec celle d'anciennes données\n",
    "\n",
    "=> **Essayons de développer le premier cas**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 3** : Splitter le jeu de données de test *(X_test)* en 2 sous échantillons (respectivement *ech1* & *ech2*) de tailles égales. En utilisant le Random Forest déjà entraîné, calculez et stockez les prédictions associées à ces 2 sous échantillons. Calculez en ensuite la moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.977142857142855 21.662823529411764\n"
     ]
    }
   ],
   "source": [
    "idx = round(len(X_test)/2)\n",
    "ech1 = X_test.iloc[:idx,:]\n",
    "ech2 = X_test.iloc[idx:,:]\n",
    "\n",
    "pred_ech1 = rf.predict(ech1)\n",
    "pred_ech2 = rf.predict(ech2)\n",
    "print(np.mean(pred_ech1),np.mean(pred_ech2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constater que les prédictions moyennes sont relativement différentes sur les 2 échantillons.\n",
    "\n",
    "**Exerice 4** : Appliquer la décomposition vue au dessus sur les 2 sous échantillons *ech1* et *ech2*. On notera *prediction1, biais1* et *contributions1* (respectivement *2*) les variables dans lequelles seront stockées les résultats.\n",
    "\n",
    "Moyennez ensuite les contributions par variable pour chaque sous échantillon et stockez les résultats dans deux variables, respectivement *totalc1* et *totalc2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1, biais1, contributions1 = ti.predict(rf, ech1)\n",
    "prediction2, biais2, contributions2 = ti.predict(rf, ech2)\n",
    "\n",
    "totalc1 = np.mean(contributions1, axis=0) \n",
    "totalc2 = np.mean(contributions2, axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la mesure où les biais sont les mêmes (puisque calculés sur le même échantillon d'apprentissage), la différence entre les prédictions moyennes sur les 2 sous échantillons provient uniquement des contributions des différentes variables.\n",
    "En outre, la différence entre les contributions des variables sommée est égale à la différence entre les prédictions moyennes. Ce que nous pouvons facilement vérifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3143193277310923, 1.3143193277310914)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(totalc1 - totalc2),np.mean(prediction1) - np.mean(prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 5** : Calculer les différences de contributions de chaque variable entre les 2 sous échantillons, et appuyez vous sur le dictionnaire des données disponible en début de notebook pour interpréter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTAT : 0.45\n",
      "RM : 0.43\n",
      "DIS : 0.19\n",
      "B : 0.13\n",
      "AGE : 0.11\n",
      "PTRATIO : 0.08\n",
      "RAD : 0.05\n",
      "TAX : 0.03\n",
      "ZN : 0.03\n",
      "CHAS : 0.0\n",
      "INDUS : -0.02\n",
      "CRIM : -0.07\n",
      "NOX : -0.1\n"
     ]
    }
   ],
   "source": [
    "for c, variable in sorted(zip(totalc1 - totalc2, \n",
    "                             boston.feature_names), reverse=True):\n",
    "    print('{} : {}'.format(variable, round(c, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Seconde décomposition\n",
    "\n",
    "Rendre les prévisions de nos Random Forests intérprétable semble donc assez simple, et relativement proche de ce que l'on connaît avec des modèles linéaires.\n",
    "\n",
    "Cependant, **cette décomposition est imparfaite, puisqu'elle ne prend pas en compte les intéractions entre variables.**\n",
    "Pour l'illustrer, prenons l'exemple du XOR (= ou exclusif).\n",
    "\n",
    "##### 1.2.3.1 L'exemple du XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Sortie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2  Sortie\n",
       "0   0   0       0\n",
       "1   0   1       1\n",
       "2   1   0       1\n",
       "3   1   1       0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'X1': [0, 0, 1, 1], 'X2': [0, 1, 0, 1], 'Sortie': [0, 1, 1, 0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le **XOR** est relativement facile à comprendre. Pour que la valeur de sortie soit Vraie (=1), il faut que l'une seule des valeurs de *X1* ou *X2* soit Vraie (=1).\n",
    "\n",
    "Dans ce cas, ni *X1* ni *X2* n'apporte de l'information sur la valeur de sortie seul. C'est à dire que si l'on isole *X1* ou *X2*, il n'est pas possible de prédire la valeur de *Sortie*.\n",
    "\n",
    "Un arbre de décision va être capable d'apprendre de cet effet et donc de classifier correctement le XOR (arbre ci dessous).\n",
    "\n",
    "<img src=\"Tree.png\" alt=\"Drawing\" style=\"width: 400px;\" align=\"left\"/>\n",
    "\n",
    "A nouveau, si l'on se penche sur le premier noeud de l'arbre, où seul *X1* est connu, nous ne sommes pas en mesure de savoir si la valeur de *Sortie* est 1 ou 0. La meilleure prédiction possible est donc 0.5 (ce qui revient à dire \"Je ne sais pas\"). De ce fait, la contribution de *X1* si l'on ne considère que ce noeud serait (à tord) 0. \n",
    "\n",
    "Au noeud suivant de l'arbre, nous prenons connaissance de la valeur de *X2*. Nous pouvons donc aisément réaliser la bonne prédiction.\n",
    "Toutefois, attribuer la bonne prédiction à la variable *X2* seule serait faux, puisque **c'est l'intéraction des deux variables qui nous permet de bien prédire la valeur de *sortie*.**\n",
    "Il faut donc répartir la contribution équitablement entre les deux variables.\n",
    "\n",
    "Prenons le <font color='red'>chemin rouge</font> à titre d'exemple. Ce chemin conduit à la prédiction de la valeur 0.\n",
    "\n",
    "On sait que la prédiction moyenne du modèle est de 0.50 (=2/4). Pour prédire la valeur 0.00, la contribution de *X1* (i.e. premier noeud) est de 0.00. Et la contribution de l'intéraction *X1X2* est de -0.50.\n",
    "\n",
    "On a donc bien :\n",
    "<center> $ 0.00 = 0.50 (contrib X1) - 0.5 (contrib X1X2) $ </center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les **effets d'intéractions** peuvent être calculés par le package **treeinterpreter** en passant le paramètre *joint_contribution=True* à la fonction *.predict*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 6**:  Repartir des 2 sous échantillons *ech1* et *ech2* construit à l'**Exercice 3**. Appliquer de nouveau la décomposition vue à l'exercice 4 en faisant attention à inclure les effets d'intéractions. Stockez à nouveau les résultats dans les variables *prediction1, bias1, contributions1* (respectivement *2* pour l'*ech2*)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1, bias1, contributions1 = ti.predict(rf, ech1, joint_contribution=True)\n",
    "prediction2, bias2, contributions2 = ti.predict(rf, ech2, joint_contribution=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction aggregated_contribution du module utils (utils.aggregated_contribution), avec en paramètre les contributions obtenues par la fonction .predict est très utile lorsque l'on utilise des effets d'intéractions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(5, 7, 9, 11, 12): array([0.01897795]),\n",
       " (4, 5, 12): array([-0.01025543]),\n",
       " (5, 9, 11, 12): array([0.00703231]),\n",
       " (5, 7, 9): array([0.00735771]),\n",
       " (0, 5, 7, 9, 10, 12): array([0.0085119]),\n",
       " (5, 9, 10, 12): array([0.0064087]),\n",
       " (12,): array([0.0442942]),\n",
       " (5, 9, 12): array([0.01418146]),\n",
       " (5, 6, 10, 12): array([-0.01833973]),\n",
       " (5, 6, 7, 10, 12): array([0.00697784]),\n",
       " (0, 5, 6, 7, 9, 10, 12): array([0.00349838]),\n",
       " (4, 5, 7, 10, 12): array([0.00652315]),\n",
       " (2, 5, 7, 9, 12): array([0.00524762]),\n",
       " (5, 7, 8, 9, 11): array([0.00084184]),\n",
       " (0, 5, 9, 10, 12): array([-0.0096962]),\n",
       " (0, 5, 10, 11, 12): array([0.01533069]),\n",
       " (5, 12): array([0.22056535]),\n",
       " (5, 7): array([0.03366707]),\n",
       " (4, 5, 7, 12): array([0.00468152]),\n",
       " (5, 7, 10, 12): array([0.03994283]),\n",
       " (5, 7, 9, 11): array([-0.00125]),\n",
       " (5,): array([0.23839139]),\n",
       " (5, 10, 12): array([0.09733232]),\n",
       " (5, 7, 12): array([0.01339164]),\n",
       " (5, 7, 9, 10, 12): array([0.00825132]),\n",
       " (5, 10, 11, 12): array([0.03105599]),\n",
       " (5, 7, 9, 12): array([-0.014303]),\n",
       " (5, 7, 8, 12): array([0.02267758]),\n",
       " (0, 5, 6, 7, 8, 9, 11, 12): array([-0.00206448]),\n",
       " (0, 1, 5, 7, 10, 12): array([-0.0025359]),\n",
       " (0, 1, 5, 12): array([0.01006035]),\n",
       " (0, 1, 5, 10, 12): array([-0.00293493]),\n",
       " (0, 4, 5, 6, 7, 8, 9, 11, 12): array([-0.00133333]),\n",
       " (0, 5, 7, 10, 11, 12): array([-0.00291667]),\n",
       " (0, 5, 12): array([-0.07767455]),\n",
       " (0, 5, 7, 8, 9, 11, 12): array([-0.00421205]),\n",
       " (0, 5, 6, 7, 10, 12): array([0.00306638]),\n",
       " (5, 7, 8, 9, 10, 12): array([0.0039881]),\n",
       " (2, 5, 7, 8, 12): array([-0.00265306]),\n",
       " (0, 5, 10, 12): array([0.00047238]),\n",
       " (0, 5, 7, 10, 12): array([-0.00041667]),\n",
       " (5, 7, 8, 9, 11, 12): array([-0.00508671]),\n",
       " (7, 12): array([-0.02472102]),\n",
       " (0, 7, 9, 12): array([-0.00566757]),\n",
       " (0, 7, 12): array([0.00965064]),\n",
       " (0, 4, 11, 12): array([0.00197846]),\n",
       " (0, 6, 7, 9, 11, 12): array([0.00021825]),\n",
       " (0, 4, 7, 11, 12): array([-0.00618311]),\n",
       " (0, 4, 5, 7, 11, 12): array([5.12156455e-18]),\n",
       " (7, 9, 12): array([0.00788585]),\n",
       " (0, 5, 7, 9, 12): array([-0.00356641]),\n",
       " (0, 12): array([-0.08148901]),\n",
       " (0, 4, 7, 12): array([-0.05539849]),\n",
       " (0, 4, 12): array([0.00593521]),\n",
       " (4, 7, 12): array([0.00079586]),\n",
       " (0, 4, 6, 11, 12): array([-0.00126134]),\n",
       " (0, 4, 5, 7, 12): array([-0.00834609]),\n",
       " (0, 4, 6, 7, 11, 12): array([0.00137755]),\n",
       " (4, 12): array([-0.00039709]),\n",
       " (0, 7, 9, 11, 12): array([-0.00054989]),\n",
       " (0, 5, 7, 9, 11, 12): array([-0.00424651]),\n",
       " (0, 5, 6, 7, 9, 11, 12): array([-0.00396825]),\n",
       " (0, 4, 5, 12): array([-0.0252928]),\n",
       " (4, 7, 11, 12): array([0.01461224]),\n",
       " (2, 5, 6, 7, 9, 12): array([0.00128968]),\n",
       " (0, 5, 6, 12): array([-0.00919989]),\n",
       " (5, 6, 7, 12): array([0.00071665]),\n",
       " (5, 8, 10, 11, 12): array([-0.00618354]),\n",
       " (0, 5, 7, 12): array([0.01204609]),\n",
       " (0, 2, 5, 6, 7, 12): array([-5.58608059e-05]),\n",
       " (0, 2, 5, 7, 8, 9, 11, 12): array([-0.01006181]),\n",
       " (2, 5, 6, 7, 12): array([0.00689243]),\n",
       " (5, 6, 8, 10, 11, 12): array([-0.00290122]),\n",
       " (4, 5, 6, 8, 10, 11, 12): array([2.38095238e-05]),\n",
       " (5, 7, 10, 11, 12): array([0.00342211]),\n",
       " (4, 7, 10, 12): array([-0.0061553]),\n",
       " (6, 7, 12): array([-0.02236156]),\n",
       " (0, 4, 5, 6, 12): array([-0.0067948]),\n",
       " (4, 6, 7, 9, 10, 12): array([-0.00166103]),\n",
       " (5, 7, 8, 10, 12): array([0.00134648]),\n",
       " (0, 4, 6, 7, 9, 10, 12): array([0.00066667]),\n",
       " (4, 6, 7, 10, 12): array([-0.00250396]),\n",
       " (5, 6, 7, 9, 12): array([0.01197596]),\n",
       " (3, 6, 7, 11, 12): array([-0.00274934]),\n",
       " (3, 6, 7, 12): array([0.00342536]),\n",
       " (5, 7, 11, 12): array([-0.00498547]),\n",
       " (0, 6, 7, 11, 12): array([0.00267857]),\n",
       " (0, 3, 6, 7, 11, 12): array([0.00071429]),\n",
       " (5, 6, 7, 11, 12): array([-0.0010189]),\n",
       " (6, 7, 11, 12): array([-0.00204115]),\n",
       " (0, 7, 11, 12): array([0.0050439]),\n",
       " (0, 6, 7, 12): array([0.00190476]),\n",
       " (0, 5, 7, 11, 12): array([0.00715675]),\n",
       " (1, 5, 7, 9, 12): array([-0.00071429]),\n",
       " (0, 1, 5, 7, 8, 12): array([-0.00054563]),\n",
       " (0, 2, 5, 11, 12): array([0.00158333]),\n",
       " (0, 5, 7, 8, 9, 10, 12): array([-0.00068027]),\n",
       " (5, 7, 8, 9, 12): array([-0.00777486]),\n",
       " (5, 8, 9, 10, 12): array([-0.00579561]),\n",
       " (1, 5, 7, 8, 10, 12): array([0.00476791]),\n",
       " (2, 5, 7, 8, 9, 12): array([-0.00452513]),\n",
       " (1, 2, 5, 7, 8, 9, 12): array([0.00303571]),\n",
       " (2, 5, 7, 12): array([-0.00159456]),\n",
       " (0, 1, 5, 7, 12): array([-0.01477976]),\n",
       " (2, 5, 12): array([0.00862616]),\n",
       " (1, 2, 5, 6, 7, 8, 9, 12): array([0.00196429]),\n",
       " (0, 1, 5, 6, 7, 8, 12): array([-0.00222222]),\n",
       " (4, 5, 7, 9, 11, 12): array([0.00316114]),\n",
       " (2, 5, 11, 12): array([-0.02117657]),\n",
       " (4, 5, 6, 7, 9, 11, 12): array([-0.00772066]),\n",
       " (2, 4, 5, 7, 12): array([-0.00195238]),\n",
       " (5, 7, 9, 10, 11, 12): array([0.00472534]),\n",
       " (1, 2, 5, 7, 8, 10, 12): array([-0.00112271]),\n",
       " (0, 2, 5, 10, 12): array([-0.00343458]),\n",
       " (0, 5, 8, 9, 10, 12): array([-0.0062224]),\n",
       " (0, 2, 5, 6, 11, 12): array([-0.00033333]),\n",
       " (0, 2, 5, 6, 9, 12): array([0.00095919]),\n",
       " (0, 4, 6, 7, 10, 11, 12): array([-0.00047619]),\n",
       " (2, 4, 5, 10, 12): array([-0.01095373]),\n",
       " (0, 2, 4, 7, 11, 12): array([-0.00031746]),\n",
       " (2, 4, 5, 7, 10, 11, 12): array([0.00080357]),\n",
       " (4, 5, 10, 12): array([0.0046421]),\n",
       " (0, 5, 6, 9, 11, 12): array([-0.00071098]),\n",
       " (2, 4, 5, 6, 11, 12): array([0.00653912]),\n",
       " (4, 5, 6, 7, 11, 12): array([0.00398238]),\n",
       " (0, 4, 5, 11, 12): array([0.00442063]),\n",
       " (0, 5, 9, 12): array([0.02257561]),\n",
       " (4, 5, 7, 10, 11, 12): array([-0.00182197]),\n",
       " (6, 7, 10, 11, 12): array([-0.00030824]),\n",
       " (2, 4, 5, 6, 10, 11, 12): array([-0.00257937]),\n",
       " (2, 4, 5, 9, 10, 12): array([-0.00155811]),\n",
       " (0, 5, 6, 9, 12): array([-0.00226903]),\n",
       " (2, 4, 5, 12): array([-0.01738923]),\n",
       " (0, 2, 5, 6, 12): array([-0.00874145]),\n",
       " (7, 11, 12): array([-0.00386045]),\n",
       " (4, 6, 7, 9, 10, 11, 12): array([0.00030423]),\n",
       " (0, 6, 7, 10, 11, 12): array([-0.0023648]),\n",
       " (0, 2, 5, 6, 9, 11, 12): array([0.00012843]),\n",
       " (2, 4, 5, 6, 12): array([-0.01231122]),\n",
       " (0, 2, 4, 5, 9, 10, 12): array([0.00153274]),\n",
       " (4, 6, 7, 10, 11, 12): array([-0.00169511]),\n",
       " (11, 12): array([0.00650128]),\n",
       " (4, 5, 6, 7, 10, 11, 12): array([0.00267857]),\n",
       " (0, 5, 6, 7, 12): array([-0.00045133]),\n",
       " (3, 5, 6, 7, 11, 12): array([-0.00166667]),\n",
       " (0, 7, 10, 11, 12): array([-0.00013889]),\n",
       " (0, 4, 5, 7, 10, 11, 12): array([-0.00122024]),\n",
       " (4, 5, 6, 7, 12): array([0.00562453]),\n",
       " (4, 7, 9, 10, 12): array([0.00282107]),\n",
       " (0, 5, 7, 8, 9, 10, 11, 12): array([-0.00129252]),\n",
       " (1, 7, 9, 10, 11, 12): array([-0.0015873]),\n",
       " (0, 5, 6, 7, 8, 9, 10, 11, 12): array([0.00045918]),\n",
       " (2, 4, 5, 7, 10, 12): array([-0.00089286]),\n",
       " (5, 6, 7, 8, 10, 12): array([-0.00119738]),\n",
       " (1, 4, 5, 6, 7, 12): array([0.00132653]),\n",
       " (6, 7, 10, 12): array([0.00768707]),\n",
       " (4, 7, 9, 12): array([-0.00262662]),\n",
       " (7, 9, 10, 12): array([0.00434921]),\n",
       " (7, 10, 12): array([-0.00242517]),\n",
       " (1, 7, 9, 10, 12): array([-0.00059524]),\n",
       " (2, 5, 10, 12): array([0.00126136]),\n",
       " (2, 5, 6, 8, 10, 11, 12): array([-0.00014881]),\n",
       " (5, 6, 7, 9, 10, 12): array([0.00631743]),\n",
       " (2, 5, 6, 10, 12): array([0.00087302]),\n",
       " (1, 5, 9, 10, 12): array([-0.00375]),\n",
       " (2, 5, 6, 7, 9, 10, 12): array([0.00416883]),\n",
       " (2, 5, 6, 10, 11, 12): array([-0.00018849]),\n",
       " (0, 1, 5, 6, 7, 12): array([0.00095238]),\n",
       " (0, 4, 5, 7, 9, 12): array([0.00134127]),\n",
       " (2, 5, 6, 8, 9, 10, 11, 12): array([-5.95238095e-05]),\n",
       " (5, 6, 7, 10, 11, 12): array([-0.00122732]),\n",
       " (0, 3, 5, 7, 9, 12): array([-0.00457143]),\n",
       " (0, 3, 5, 9, 12): array([-0.00179221]),\n",
       " (4, 7, 10, 11, 12): array([-0.00113095]),\n",
       " (0, 5, 6, 7, 10, 11, 12): array([-0.00059127]),\n",
       " (5, 6, 7, 8, 11, 12): array([0.00160053]),\n",
       " (4, 11, 12): array([0.0100202]),\n",
       " (4, 5, 8, 9, 10, 12): array([0.00035714]),\n",
       " (0, 2, 5, 10, 11, 12): array([0.00096032]),\n",
       " (0, 2, 5, 7, 10, 11, 12): array([4.29550575e-18]),\n",
       " (0, 5, 6, 7, 8, 10, 12): array([-0.0004828]),\n",
       " (0, 1, 5, 6, 7, 10, 12): array([0.00011905]),\n",
       " (4, 6, 7, 8, 9, 10, 12): array([-0.00019841]),\n",
       " (0, 4, 5, 6, 7, 8, 10, 12): array([0.00017857]),\n",
       " (4, 5, 6, 7, 9, 10, 12): array([-0.00685999]),\n",
       " (2, 4, 5, 6, 7, 9, 11, 12): array([9.52380952e-05]),\n",
       " (5, 6, 7, 9, 11, 12): array([0.00050397]),\n",
       " (4, 5, 6, 7, 8, 10, 12): array([-0.00198413]),\n",
       " (0, 2, 5, 6, 7, 9, 11, 12): array([-1.98412698e-05]),\n",
       " (0, 4, 5, 6, 7, 8, 10, 11, 12): array([-3.96825397e-05]),\n",
       " (4, 5, 7, 9, 10, 12): array([-8.73015873e-05]),\n",
       " (0, 4, 5, 6, 10, 12): array([-0.0045432]),\n",
       " (2, 4, 5, 6, 8, 9, 10, 11, 12): array([-3.96825397e-05]),\n",
       " (4, 5, 6, 7, 8, 10, 11, 12): array([0.00044643]),\n",
       " (2, 4, 5, 8, 9, 10, 11, 12): array([-0.00175519]),\n",
       " (0, 4, 5, 6, 7, 9, 10, 12): array([-0.00029762]),\n",
       " (2, 4, 5, 8, 9, 10, 12): array([-0.00071023]),\n",
       " (2, 5, 6, 7, 9, 11, 12): array([-0.00012698]),\n",
       " (4, 5, 6, 7, 8, 9, 10, 12): array([0.00012698]),\n",
       " (0, 2, 4, 5, 6, 12): array([0.00215873]),\n",
       " (3, 4, 5, 12): array([0.00614286]),\n",
       " (5, 6, 8, 9, 10, 11, 12): array([-3.96825397e-05]),\n",
       " (3, 4, 5, 8, 12): array([0.001]),\n",
       " (3, 4, 12): array([-0.00316027]),\n",
       " (0, 4, 5, 8, 9, 10, 12): array([0.00047619]),\n",
       " (2, 5, 6, 7, 10, 11, 12): array([0.00039683]),\n",
       " (0, 6, 7, 10, 12): array([0.00062794]),\n",
       " (6, 7, 8, 10, 12): array([-0.00031548]),\n",
       " (4, 6, 7, 8, 10, 12): array([0.00026786]),\n",
       " (0, 5, 6, 7, 9, 12): array([0.00108333]),\n",
       " (2, 5, 7, 9, 10, 12): array([0.00095238]),\n",
       " (2, 4, 5, 7, 9, 10, 12): array([5.95238095e-05]),\n",
       " (0, 1, 5, 7, 10, 11, 12): array([-0.00011905]),\n",
       " (0, 4, 7, 9, 12): array([-0.00087302]),\n",
       " (0, 4, 6, 7, 12): array([1.88964475e-06]),\n",
       " (2, 4, 7, 11, 12): array([-0.00232143]),\n",
       " (0, 4, 6, 12): array([-0.00200582]),\n",
       " (0, 2, 4, 5, 6, 11, 12): array([-0.00090476]),\n",
       " (6, 7, 8, 12): array([0.00146825]),\n",
       " (0, 2, 4, 5, 6, 7, 11, 12): array([0.00030952]),\n",
       " (0, 11, 12): array([-0.01184168]),\n",
       " (0, 3, 5, 11, 12): array([0.01017857]),\n",
       " (0, 2, 4, 6, 10, 12): array([-0.00011905]),\n",
       " (0, 3, 11, 12): array([-0.00112374]),\n",
       " (0, 2, 4, 6, 12): array([8.92857143e-05]),\n",
       " (5, 6, 7, 8, 10, 11, 12): array([0.00198413]),\n",
       " (4, 5, 11, 12): array([0.00240079]),\n",
       " (0, 4, 5, 6, 7, 9, 11, 12): array([0.00037628]),\n",
       " (0, 6, 11, 12): array([0.00165816]),\n",
       " (0, 6, 12): array([0.00189935]),\n",
       " (0, 5, 6, 7, 8, 10, 11, 12): array([-0.00041667]),\n",
       " (0, 2, 4, 5, 7, 8, 9, 11, 12): array([0.00044643]),\n",
       " (6, 7, 9, 12): array([0.0006746]),\n",
       " (6, 7, 9, 11, 12): array([0.00011905]),\n",
       " (0, 4, 5, 6, 7, 12): array([0.00021429]),\n",
       " (1, 4, 5, 7, 11, 12): array([4.29550575e-18]),\n",
       " (2, 5, 6, 12): array([-0.00809524]),\n",
       " (5, 6, 7, 9): array([0.00723498]),\n",
       " (2, 5, 6, 7, 9, 10): array([-0.00264881]),\n",
       " (5, 6, 7, 9, 10): array([1.7182023e-17]),\n",
       " (1, 5, 9, 10, 11, 12): array([0.00083333]),\n",
       " (0, 1, 2, 5, 6, 7, 9, 10): array([-4.13029399e-18]),\n",
       " (4, 5, 6, 7, 10, 12): array([0.0002381]),\n",
       " (4, 5, 7, 11, 12): array([-0.0071875]),\n",
       " (0, 2, 5, 6, 7, 9, 10): array([0.00229167]),\n",
       " (5, 6, 7, 9, 10, 11, 12): array([-3.96825397e-05]),\n",
       " (0, 5, 6, 8, 11, 12): array([0.00142857]),\n",
       " (0, 5, 8, 12): array([0.00109821]),\n",
       " (0, 2, 5, 9, 10, 12): array([-0.00597884]),\n",
       " (0, 5, 8, 11, 12): array([0.00144345]),\n",
       " (6, 8, 11, 12): array([-0.00015873]),\n",
       " (6, 11, 12): array([0.00327492]),\n",
       " (6, 7, 8, 11, 12): array([3.96825397e-05]),\n",
       " (2, 5, 6, 7, 11, 12): array([-0.00050759]),\n",
       " (0, 2, 5, 7, 8, 9, 10, 11, 12): array([0.00077381]),\n",
       " (2, 4, 5, 6, 7, 11, 12): array([0.00384921]),\n",
       " (0, 2, 4, 6, 7, 10, 11, 12): array([-0.00039116]),\n",
       " (0, 2, 4, 7, 10, 11, 12): array([0.0005102]),\n",
       " (0, 2, 4, 10, 11, 12): array([-0.00036111]),\n",
       " (0, 2, 4, 12): array([-0.00776355]),\n",
       " (4, 6, 7, 11, 12): array([-7.93650794e-05]),\n",
       " (0, 2, 4, 11, 12): array([-0.0001873]),\n",
       " (0, 2, 4, 5, 7, 10, 11, 12): array([0.00047619]),\n",
       " (0, 1, 5, 9, 10, 12): array([-0.00178095]),\n",
       " (0, 2, 5, 6, 7, 10, 11, 12): array([0.0015873]),\n",
       " (0, 1, 5, 6, 9, 10, 12): array([0.00212302]),\n",
       " (0, 2, 5, 7, 8, 9, 12): array([0.00074735]),\n",
       " (0, 5, 6, 9, 10, 12): array([0.00623214]),\n",
       " (0, 1, 2, 5, 6, 9, 10, 12): array([0.00011905]),\n",
       " (0, 5, 7, 8, 9, 12): array([-0.00073413]),\n",
       " (0, 2, 5, 6, 7, 8, 10, 11, 12): array([0.0018254]),\n",
       " (0, 5, 6, 7, 9, 10, 11, 12): array([0.00025162]),\n",
       " (0, 4, 5, 7, 10, 12): array([0.00450893]),\n",
       " (0, 2, 5, 6, 7, 10, 12): array([-0.00308303]),\n",
       " (0, 5, 7, 8, 12): array([0.002]),\n",
       " (0, 2, 5, 7, 8, 10, 12): array([0.00011905]),\n",
       " (0, 5, 8, 10, 12): array([0.00190476]),\n",
       " (0, 2, 5, 7, 10, 12): array([0.00069048]),\n",
       " (0, 5, 7, 8, 10, 12): array([-0.00076099]),\n",
       " (1, 5, 6, 7, 8, 10, 11, 12): array([-5.95238095e-05]),\n",
       " (0, 5, 7, 8, 10, 11, 12): array([-0.0030119]),\n",
       " (1, 5, 6, 7, 8, 10, 12): array([-0.00052778]),\n",
       " (0, 5, 9, 11, 12): array([0.00045635]),\n",
       " (3, 4, 5, 6, 7, 11, 12): array([-0.00053571]),\n",
       " (5, 8, 9, 10, 11, 12): array([-0.00143141]),\n",
       " (0, 1, 5, 6, 9, 10, 11, 12): array([3.96825397e-05]),\n",
       " (0, 1, 5, 6, 8, 9, 10, 11, 12): array([0.00035714]),\n",
       " (5, 6, 9, 10, 12): array([0.00360714]),\n",
       " (0, 5, 6, 7, 9, 10): array([-0.00065476]),\n",
       " (2, 5, 9, 11, 12): array([-0.01464286]),\n",
       " (0, 7, 8, 12): array([0.00181548]),\n",
       " (2, 4, 5, 11, 12): array([-0.00087302]),\n",
       " (2, 4, 6, 7, 12): array([0.00089286]),\n",
       " (4, 5, 6, 7, 9, 10, 11, 12): array([-0.00034014]),\n",
       " (0, 4, 5, 6, 9, 11, 12): array([0.00031746]),\n",
       " (2, 4, 7, 12): array([0.01490079]),\n",
       " (0, 2, 4, 5, 7, 8, 9, 10, 12): array([0.0012619]),\n",
       " (0, 4, 5, 6, 7, 9, 10, 11, 12): array([0.00014456]),\n",
       " (1, 6, 7, 11, 12): array([0.00014881]),\n",
       " (0, 2, 4, 5, 8, 9, 10, 12): array([-0.00085714]),\n",
       " (0, 4, 5, 10, 11, 12): array([0.00031746]),\n",
       " (5, 6, 11, 12): array([-0.00277778]),\n",
       " (0, 3, 4, 12): array([0.00320437]),\n",
       " (0, 3, 4, 9, 12): array([-0.00031746]),\n",
       " (0, 6, 7, 8, 10, 11, 12): array([-8.5910115e-18]),\n",
       " (4, 5, 7, 8, 12): array([0.00021755]),\n",
       " (4, 5, 7, 8, 10, 12): array([1.48809524e-05]),\n",
       " (0, 4, 5, 7, 9, 11, 12): array([-0.00035714]),\n",
       " (5, 6, 9, 12): array([-0.00292092]),\n",
       " (5, 6, 7): array([0.00345238]),\n",
       " (4, 5, 7): array([0.00345238]),\n",
       " (2, 5, 7, 8, 10, 12): array([0.0010119]),\n",
       " (0, 5, 6, 7, 11, 12): array([0.00119841]),\n",
       " (2, 4, 5, 6, 7, 9, 10, 11, 12): array([7.93650794e-05]),\n",
       " (2, 4, 5, 6, 7, 9, 10, 12): array([0.00046685]),\n",
       " (0, 4, 5, 6, 10, 11, 12): array([-0.00107143]),\n",
       " (1, 5, 9, 12): array([0.04798942]),\n",
       " (4, 6, 10, 11, 12): array([-0.01031746]),\n",
       " (3, 5, 10, 11, 12): array([0.00313657]),\n",
       " (5, 8, 12): array([0.00689286]),\n",
       " (4, 5, 7, 9, 10, 11, 12): array([-9.52380952e-05]),\n",
       " (5, 7, 10): array([-0.00419841]),\n",
       " (0, 2, 5, 12): array([3.40136054e-05]),\n",
       " (5, 8, 10, 12): array([-0.00847222]),\n",
       " (6, 12): array([0.00153686]),\n",
       " (5, 7, 10, 11): array([0.00079365]),\n",
       " (4, 6, 11, 12): array([0.00210317]),\n",
       " (3, 5, 8, 10, 11, 12): array([0.00040179]),\n",
       " (1, 5, 7, 9, 10, 12): array([0.00083333]),\n",
       " (5, 7, 8, 9, 10, 11, 12): array([-2.97619048e-05]),\n",
       " (3, 4, 5, 7, 12): array([0.00059524]),\n",
       " (2, 5, 6, 11, 12): array([-0.00198413]),\n",
       " (5, 7, 8, 10, 11, 12): array([-0.00044643]),\n",
       " (0, 5, 7, 9): array([-0.00121429]),\n",
       " (0, 4, 5, 6, 11, 12): array([-0.00029762]),\n",
       " (0, 4, 5, 7, 8, 9, 10, 12): array([-0.00035714]),\n",
       " (2, 4, 5, 7, 9, 12): array([0.00020238]),\n",
       " (1, 5, 10, 12): array([0.00053571]),\n",
       " (2, 5, 8, 11, 12): array([0.00031746]),\n",
       " (4, 5, 8, 10, 12): array([0.00142857]),\n",
       " (1, 5, 9, 11, 12): array([0.00119048]),\n",
       " (9, 11, 12): array([-0.00094048]),\n",
       " (5, 11, 12): array([-0.00324993]),\n",
       " (2, 3, 4, 5, 6, 10, 11, 12): array([-3.96825397e-05]),\n",
       " (4, 5, 6, 10, 12): array([0.00031746]),\n",
       " (0, 2, 5, 6, 10, 12): array([0.00017857]),\n",
       " (2, 5, 9, 12): array([0.00160714]),\n",
       " (0, 2, 5, 6, 7, 8, 9, 12): array([0.00057823]),\n",
       " (0, 1, 4, 5, 6, 9, 10, 12): array([0.00060516]),\n",
       " (0, 1, 4, 5, 6, 7, 9, 10, 12): array([0.00020833]),\n",
       " (0, 2, 5, 6, 7, 8, 9, 10, 12): array([-0.00331633]),\n",
       " (2, 4, 5, 7, 8, 9, 10, 11, 12): array([0.00047619]),\n",
       " (2, 4, 5, 7, 8, 9, 10, 12): array([-0.00027211]),\n",
       " (2, 5, 9, 10, 12): array([-0.00134271]),\n",
       " (1, 5, 7, 12): array([-0.00507143]),\n",
       " (1, 2, 4, 5, 7, 9, 12): array([-0.00029762]),\n",
       " (2, 5, 7, 11, 12): array([0.0032483]),\n",
       " (1, 5, 7, 10, 12): array([0.00045635]),\n",
       " (0, 1, 5, 7, 9, 10, 12): array([0.00017857]),\n",
       " (2, 5, 6, 7, 9, 10, 11, 12): array([0.00057143]),\n",
       " (0, 2, 5, 7, 9, 12): array([0.00017857]),\n",
       " (1, 5, 7, 9, 11, 12): array([0.00040816]),\n",
       " (2, 4, 5, 6, 7, 9, 12): array([0.00118254]),\n",
       " (0, 9, 11, 12): array([-0.00083333]),\n",
       " (2, 4, 5, 6, 7, 8, 9, 12): array([-0.00015873]),\n",
       " (2, 6, 10, 12): array([-0.00267857]),\n",
       " (6, 10, 12): array([0.01152778]),\n",
       " (0, 6, 7, 8, 9, 10, 11, 12): array([-5.95238095e-05]),\n",
       " (2, 4, 5, 9, 12): array([-0.00066667]),\n",
       " (0, 2, 4, 5, 6, 7, 9, 10): array([0.000625]),\n",
       " (0, 2, 5, 8, 10, 11, 12): array([0.00043651]),\n",
       " (0, 5, 8, 10, 11, 12): array([0.00054563]),\n",
       " (0, 1, 2, 5, 10, 11, 12): array([0.00059524]),\n",
       " (0, 1, 5, 10, 11, 12): array([0.00279762]),\n",
       " (5, 6, 9, 11, 12): array([0.00563492]),\n",
       " (0, 4, 5, 6, 7, 8, 12): array([0.00014286]),\n",
       " (0, 2, 4, 5, 6, 7, 12): array([0.00103175]),\n",
       " (5, 6, 10, 11, 12): array([0.0022619]),\n",
       " (0, 1, 5, 7, 9, 10, 11, 12): array([-0.00011905]),\n",
       " (3, 4, 5, 10, 11, 12): array([0.00190476]),\n",
       " (4, 5, 10, 11, 12): array([0.00054422]),\n",
       " (0, 4, 8, 11, 12): array([-0.00027211]),\n",
       " (0, 2, 5, 6, 7, 11, 12): array([0.002]),\n",
       " (2, 5, 7, 9, 10, 11, 12): array([0.00034014]),\n",
       " (0, 2, 5, 7, 9, 10, 11, 12): array([0.00090136]),\n",
       " (0, 2, 5, 9, 10, 11, 12): array([-0.0024966]),\n",
       " (3, 4, 6, 7, 10, 11, 12): array([-5.95238095e-05]),\n",
       " (3, 6, 7, 10, 11, 12): array([8.92857143e-05]),\n",
       " (3, 6, 7, 8, 12): array([0.00130952]),\n",
       " (0, 3, 7, 11, 12): array([-0.00027778]),\n",
       " (4, 5, 6, 7, 8, 12): array([-0.00020833]),\n",
       " (0, 5, 6, 10, 12): array([0.00690476]),\n",
       " (0, 2, 4, 6, 10, 11, 12): array([0.00025794]),\n",
       " (1, 5, 7, 9, 10, 11, 12): array([-0.00088435])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_contrib1 = utils.aggregated_contribution(contributions1)\n",
    "mean_contrib2 = utils.aggregated_contribution(contributions2)\n",
    "mean_contrib1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 7** : Observez le contenu de la variable *mean_contrib1*. Quel est son type ? A quoi correspond son contenu ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"text-decoration:underline\">Réponse</span> : C'est un dictionnaire dont les clés représentent les indices des variables des données de Boston, et dont les valeurs représentent la contribution moyenne pour la/les variables correspondant(es)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 8** : Vérifiez que la différence entre les contributions des variables (et intéractions de variables) sommée est égale à la différence entre les prédictions moyennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3143193277310927, 1.3143193277310914)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list(mean_contrib1.values())) - np.sum(list(mean_contrib2.values())),np.mean(prediction1) - np.mean(prediction2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 9** : En sachant que pour un indice de variable donné, il est possible d'en récupérer le nom via le code suivant :\n",
    "`indice_variable = 1\n",
    "boston[\"feature_names\"][indice_variable]`\n",
    "\n",
    "\n",
    "Calculer de nouveau les différences de contributions entre les 2 sous échantillons, en prenant cette fois en compte les intéractions entre variables.\n",
    "Afficher par exemple, les 10 variables/intéractions de variables qui ont le plus contribuées aux écarts de prix entre les 2 échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LSTAT'] [0.28211923]\n",
      "['RM'] [0.26142737]\n",
      "['RM', 'DIS', 'LSTAT'] [0.24928681]\n",
      "['RM', 'LSTAT'] [0.21326153]\n",
      "['RM', 'PTRATIO', 'LSTAT'] [0.07639257]\n",
      "['CRIM', 'NOX', 'DIS', 'LSTAT'] [-0.06303489]\n",
      "['RM', 'PTRATIO', 'B', 'LSTAT'] [0.03671815]\n",
      "['ZN', 'RM', 'TAX', 'LSTAT'] [0.03656458]\n",
      "['AGE', 'LSTAT'] [0.03570942]\n",
      "['RM', 'DIS', 'RAD', 'LSTAT'] [0.03485015]\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for k in set(mean_contrib1.keys()).union(\n",
    "              set(mean_contrib2.keys())):\n",
    "    res.append(([boston[\"feature_names\"][index] for index in k] , \n",
    "               mean_contrib1.get(k, 0) - mean_contrib2.get(k, 0)))   \n",
    "         \n",
    "for lst, v in (sorted(res, key=lambda x:-abs(x[1])))[:10]:\n",
    "    print (lst, v)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus sur les Random Forests en Classification\n",
    "\n",
    "Nous utiliserons ici le dataset **iris**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Plants Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML iris datasets.\n",
      "http://archive.ics.uci.edu/ml/datasets/Iris\n",
      "\n",
      "The famous Iris database, first used by Sir R.A Fisher\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      "References\n",
      "----------\n",
      "   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = pd.DataFrame(iris.target, columns=[\"Classe\"])\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice Bilan** : Sur la base des données *iris*, appliquez une Random Forest et utiliser le package treeinterpreter pour décomposer la prédiction pour certain point de données choisit manuellement.\n",
    "\n",
    "Les fonctions vues précédemment s'utilisent de la même manière mais les sorties sont différentes ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]]\n",
      "Prediction [[0. 1. 0.]]\n",
      "Bias (trainset prior) [[0.343 0.297 0.36 ]]\n",
      "Feature contributions:\n",
      "sepal length (cm) [-0.03914815  0.04576177 -0.00661362]\n",
      "sepal width (cm) [ 0.         -0.00013228  0.00013228]\n",
      "petal length (cm) [-0.11869931  0.44501395 -0.32631464]\n",
      "petal width (cm) [-0.18515254  0.21235656 -0.02720402]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "idx = list(range(len(iris.target)))\n",
    "np.random.shuffle(idx)\n",
    " \n",
    "rf.fit(iris.data[idx][:100], iris.target[idx][:100])\n",
    "\n",
    "instance = iris.data[idx][100:101]\n",
    "print(rf.predict_proba(instance))\n",
    "\n",
    "prediction, bias, contributions = ti.predict(rf, instance)\n",
    "print(\"Prediction\", prediction)\n",
    "print(\"Bias (trainset prior)\", bias)\n",
    "print(\"Feature contributions:\")\n",
    "for c, feature in zip(contributions[0], \n",
    "                             iris.feature_names):\n",
    "    print(feature, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "A finir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crédits\n",
    " http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
